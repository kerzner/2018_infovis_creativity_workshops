\section{Discussion}
\label{sec:discussion}

This section discusses implications and limitations of \workshops and the research methodology of critically reflective practice.

\subsection{Limitations of CVO Workshops}

Our experience across diverse domains --- from cartography to neuroscience --- provides evidence that \workshops are a valuable and general method for fostering the visualization mindset while creating artifacts that advance visualization methodologies. We argue that they achieve these goals through the use of \methods that appropriately emphasize the \topic of visualization opportunities while accounting for (inter)personal factors, including \agency, \collegiality, \challenge, \interest, and \trust. 

Yet, workshops may not be appropriate in some scenarios. Because using workshops requires researchers to ask interesting questions and potentially lead discussions about their collaborators' domain, we caution the use of workshops as the first method in a project. Traditional user-centered approaches should be used to learn domain vocabulary and explore the feasibility of collaboration. In the project that did not result in ongoing collaboration~[\ref{pro:updb}], we lacked the domain knowledge needed to effectively design the workshop. Also, our collaborators were too busy to meet with us before the workshop, which should have been a warning about the nature of the project. Accordingly, we recommend researchers evaluate the preconditions of design studies~\cite{Sedlmair2012} in projects where they are considering workshops.

We also recognize that workshops may not be well received by all of the stakeholders. In a full-day workshop [\ref{pro:graffinity}], one participant reported that {\it ``Overall, it was good, but a bit long and slightly repetitive.''} Similarly, after another full-day workshop [\ref{pro:cp}], one participant said {\it ``There was too much time spent expanding and not enough focus \ldots discussions were too shallow and nonspecific.''} Nevertheless, both workshops were generally well received by stakeholders as they allowed us to explore a broad space of visualization opportunities. We can, however, improve future workshops by ensuring that the methods are closely related to the \topic and that we facilitate workshops in a way that provides appropriate \agency to all of the stakeholders.

More generally, whether workshops can enhance creativity is an open question~\cite{Nickerson1999,Sawyer2006}. 
Creativity is a complex phenomenon studied from many perspectives, including design~\cite{Shneiderman2005}, psychology~\cite{Sawyer2006}, sociology~\cite{Lubart1999}, and biology~\cite{Martindale1999}. The results of several controlled experiments indicate that group-based methods can reduce creativity~\cite{Bouchard1969,Mullen1991}. Yet, critics of these studies argue that they rely on contrived metrics and lack ecological validity~\cite{Hewett2005,Mayer1999}. Experimentally testing the relationship between workshops and creativity is beyond the scope of this paper. Instead, we focus on understanding and communicating how we use \workshops in applied collaborations.


\subsection{Critically Reflective Practice}

Throughout this project, we wrestled with a fundamental question: how can we rigorously learn from our diverse, collective experience? We first examined measurable attributes of workshops, such as their length, number of participants, and quantity of ideas generated. However, our workshops were conducted over 10 years in applied settings with no experimental controls. More importantly, it is difficult, if not impossible, to measure how ideas influence collaborations. Quantitative analysis, we decided, would not produce useful knowledge about how to use \workshops. 

We also considered qualitative research methodologies and methods, such as grounded theory~\cite{Corbin1990} and thematic analysis~\cite{Braun2006}. These approaches focus on extracting meaning from externalized data, but the the most meaningful and useful information about workshops resided in our collective, experiential knowledge. We therefore abandoned analysis methods that ignore (or seek to suppress) the role of experience in knowledge generation. 

We found critically reflective practice to be an appropriate approach, providing a methodology to learn from the analysis of experience, documentation, and existing theory, while allowing for the use of additional analysis methods~\cite{Brookfield1998,Thompson2008}. Due to the nature of reflection, however, the framework is not exhaustive, predictive, or objective. Nevertheless, it is consistent with our experience, grounded in existing theory, and, we argue, useful for future visualization research.

Yet, the use of reflective practice may raise questions about the validity of this work. After all, can the framework be validated without experimental data? We emphasize our choice of the term {\it framework}~\cite{Jabareen2008} because we intend for it to be evaluated by whether it provides an interpretive understanding of \workshops. Our position is that it achieves this goal because it enabled us to learn from our experience using workshops on 3 continents over the past 10 years. For example, we used the framework to identify and organize \numberOfPitfalls pitfalls to avoid in future workshops --- they are described in the Supplemental Material. This framework, however, is only a snapshot of our current understanding of \workshops, which will continue to evolve with additional research, practice, and reflection.

Given that this work results from the subjective analysis of our experience, we recognize that there could also be questions about its trustworthiness. Therefore, to increase the trustworthiness of our results, we provide an audit trail~\cite{Carcary2009,Lincoln1985} of our work that contains a timeline of our analysis and our experience as well as diverse artifacts, including comparative analysis of our workshops, presentations outlining the framework, early written drafts of our framework, and structured written reflection to elicit ideas from all of this paper's coauthors. This audit trail, in Supplemental Material, summarizes and includes \numberOfAudits of the reflective artifacts, culled from the original set to protect the privacy of internal discussions and confidential materials from our domain collaborators. 

In future reflective projects, we plan to establish guidelines that encourage transparency of reflective artifacts through  mechanisms to flag documents as on- or off-the-record. Because our research and meta-analysis would have been impossible without well-preserved documentation, we hope that the audit trail inspires future thinking on how to document and preserve the decisions in visualization collaborations. We put forth both the audit trail and our documented use of critically reflective practice as secondary contributions.